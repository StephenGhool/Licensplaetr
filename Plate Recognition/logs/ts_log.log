2022-06-09T12:53:27,093 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-06-09T12:53:27,093 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-06-09T12:53:27,460 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-06-09T12:53:27,460 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-06-09T12:53:28,517 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.6.0
TS Home: C:\Users\steph\AppData\Roaming\Python\Python39\site-packages
Current directory: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment
Temp directory: C:\Users\steph\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 8180 M
Python executable: c:\program files\python39\python.exe
Config file: logs\config\20220605132042262-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Initial Models: license_plate=license_plate.mar
Log dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Metrics dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Model config: N/A
2022-06-09T12:53:28,517 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.6.0
TS Home: C:\Users\steph\AppData\Roaming\Python\Python39\site-packages
Current directory: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment
Temp directory: C:\Users\steph\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 8180 M
Python executable: c:\program files\python39\python.exe
Config file: logs\config\20220605132042262-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Initial Models: license_plate=license_plate.mar
Log dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Metrics dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Model config: N/A
2022-06-09T12:53:28,532 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220605132042262-startup.cfg",
  "modelCount": 1,
  "created": 1654449642263,
  "models": {
    "license_plate": {
      "1.0": {
        "defaultVersion": true,
        "marName": "license_plate.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-06-09T12:53:28,532 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220605132042262-startup.cfg",
  "modelCount": 1,
  "created": 1654449642263,
  "models": {
    "license_plate": {
      "1.0": {
        "defaultVersion": true,
        "marName": "license_plate.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-06-09T12:53:28,548 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220605132042262-startup.cfg
2022-06-09T12:53:28,548 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220605132042262-startup.cfg
2022-06-09T12:53:28,550 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220605132042262-startup.cfg validated successfully
2022-06-09T12:53:28,550 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220605132042262-startup.cfg validated successfully
2022-06-09T12:53:29,344 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model license_plate
2022-06-09T12:53:29,344 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model license_plate
2022-06-09T12:53:29,345 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T12:53:29,345 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T12:53:29,347 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T12:53:29,347 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T12:53:29,348 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model license_plate loaded.
2022-06-09T12:53:29,348 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model license_plate loaded.
2022-06-09T12:53:29,349 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: license_plate, count: 1
2022-06-09T12:53:29,349 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: license_plate, count: 1
2022-06-09T12:53:29,369 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:53:29,369 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:53:29,371 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-06-09T12:53:29,371 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-06-09T12:53:31,377 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-06-09T12:53:31,377 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-06-09T12:53:31,377 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-06-09T12:53:31,377 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-06-09T12:53:31,384 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-06-09T12:53:31,384 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-06-09T12:53:31,384 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-06-09T12:53:31,384 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-06-09T12:53:31,386 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-06-09T12:53:31,386 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-06-09T12:53:33,529 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-06-09T12:53:33,529 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-06-09T12:53:33,942 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 91, in collect_all
    value(num_of_gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 61, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2022-06-09T12:53:33,942 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 91, in collect_all
    value(num_of_gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 61, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2022-06-09T12:53:36,417 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:53:36,424 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]11104
2022-06-09T12:53:36,426 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:53:36,426 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change null -> WORKER_STARTED
2022-06-09T12:53:36,426 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change null -> WORKER_STARTED
2022-06-09T12:53:36,426 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:53:36,433 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:53:36,433 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:53:36,449 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:53:36,454 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793616454
2022-06-09T12:53:36,454 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793616454
2022-06-09T12:53:36,492 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:53:45,849 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:53:45,849 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:53:45,852 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:53:45,851 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:53:45,852 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:53:45,855 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:53:45,851 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:53:45,854 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:53:45,855 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:53:45,855 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:53:45,856 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:53:45,861 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:53:45,862 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:53:45,867 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:53:45,867 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:53:45,869 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:53:45,870 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:53:45,871 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:53:45,872 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:53:45,874 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:53:45,879 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T12:53:45,880 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T12:53:45,881 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service = model_loader.load(
2022-06-09T12:53:45,883 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service = model_loader.load(
2022-06-09T12:53:45,883 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T12:53:45,884 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T12:53:45,885 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-06-09T12:53:45,885 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     initialize_fn(service.context)
2022-06-09T12:53:45,886 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_loader.py", line 180, in <lambda>
2022-06-09T12:53:45,887 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_loader.py", line 180, in <lambda>
2022-06-09T12:53:45,888 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-06-09T12:53:45,859 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:53:45,889 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-06-09T12:53:45,859 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:53:45,896 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:53:45,890 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - TypeError: handle() takes 1 positional argument but 2 were given
2022-06-09T12:53:45,895 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - TypeError: handle() takes 1 positional argument but 2 were given
2022-06-09T12:53:45,896 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:53:45,898 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:53:45,898 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:53:45,900 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:53:45,900 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:53:45,906 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:53:45,906 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:53:45,907 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T12:53:45,907 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T12:53:45,909 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:53:45,909 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:53:45,909 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:53:45,909 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:53:46,920 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:53:46,920 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:53:48,302 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:53:48,303 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]18724
2022-06-09T12:53:48,305 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:53:48,305 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:53:48,305 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:53:48,306 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:53:48,305 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:53:48,306 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:53:48,310 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793628310
2022-06-09T12:53:48,310 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793628310
2022-06-09T12:53:48,310 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:53:48,334 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:53:51,653 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:53:51,653 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:53:51,653 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:53:51,656 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:53:51,653 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:53:51,654 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:53:51,660 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:53:51,667 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:53:51,674 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:53:51,656 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:53:51,682 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:53:51,669 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:53:51,682 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:53:51,684 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:53:51,682 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:53:51,698 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:53:51,689 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:53:51,698 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:53:51,701 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:53:51,698 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:53:51,718 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:53:51,711 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:53:51,718 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:53:51,727 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:53:51,727 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T12:53:51,736 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:53:51,718 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:53:51,746 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:53:51,739 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service = model_loader.load(
2022-06-09T12:53:51,746 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T12:53:51,771 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service = model_loader.load(
2022-06-09T12:53:51,767 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T12:53:51,746 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:53:51,786 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:53:51,786 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T12:53:51,791 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:53:51,786 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:53:51,797 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T12:53:51,786 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-06-09T12:53:51,798 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:53:51,791 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:53:51,798 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:53:51,797 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T12:53:52,804 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:53:52,804 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:53:54,014 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:53:54,015 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]17164
2022-06-09T12:53:54,017 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:53:54,016 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:53:54,017 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:53:54,018 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:53:54,017 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:53:54,018 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:53:54,022 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793634022
2022-06-09T12:53:54,022 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793634022
2022-06-09T12:53:54,022 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:53:54,036 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:53:57,465 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:53:57,465 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:53:57,465 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:53:57,465 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:53:57,468 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:53:57,465 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:53:57,467 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:53:57,468 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:53:57,470 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:53:57,469 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:53:57,469 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:53:57,470 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:53:57,474 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:53:57,471 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:53:57,472 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:53:57,474 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:53:57,476 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:53:57,474 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:53:57,475 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:53:57,476 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:53:57,480 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:53:57,476 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:53:57,477 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:53:57,485 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:53:57,486 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:53:57,480 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:53:57,489 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:53:57,487 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:53:57,494 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:53:57,489 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T12:53:57,494 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:53:57,489 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:53:57,496 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-06-09T12:53:57,495 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service = model_loader.load(
2022-06-09T12:53:57,499 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:53:57,496 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-06-09T12:53:57,499 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:53:59,510 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:53:59,510 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:54:00,818 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:54:00,819 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]11740
2022-06-09T12:54:00,820 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:54:00,820 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:54:00,820 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:54:00,824 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:54:00,822 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:54:00,824 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:54:00,829 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793640829
2022-06-09T12:54:00,829 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793640829
2022-06-09T12:54:00,829 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:54:00,842 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:54:03,887 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:54:03,888 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:54:03,887 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:54:03,888 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:54:03,891 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:54:03,888 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:54:03,890 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:54:03,891 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:54:03,895 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:54:03,893 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:54:03,892 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:54:03,895 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:54:03,897 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:54:03,896 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:54:03,896 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:54:03,897 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:54:03,899 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:54:03,897 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:54:03,898 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:54:03,899 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:54:03,904 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:54:03,900 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:54:03,900 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:54:03,909 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:54:03,910 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:54:03,904 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:54:03,911 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:54:03,910 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:54:03,911 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:54:03,916 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-06-09T12:54:03,911 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:54:03,917 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:54:03,915 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T12:54:03,921 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:54:03,916 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-06-09T12:54:03,917 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:54:03,921 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:54:06,923 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:54:06,923 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:54:08,288 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:54:08,289 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]35104
2022-06-09T12:54:08,291 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:54:08,291 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:54:08,291 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:54:08,293 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:54:08,292 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:54:08,293 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:54:08,298 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793648298
2022-06-09T12:54:08,298 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793648298
2022-06-09T12:54:08,298 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:54:08,317 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:54:11,579 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:54:11,579 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:54:11,579 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:54:11,579 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:54:11,582 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:54:11,579 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:54:11,581 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:54:11,582 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:54:11,584 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:54:11,583 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:54:11,583 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:54:11,584 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:54:11,587 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:54:11,585 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:54:11,586 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:54:11,587 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:54:11,589 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:54:11,588 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:54:11,588 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:54:11,589 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:54:11,591 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:54:11,590 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:54:11,590 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:54:11,591 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:54:11,596 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:54:11,594 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:54:11,597 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:54:11,596 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:54:11,596 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:54:11,608 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-06-09T12:54:11,597 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:54:11,603 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:54:11,609 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:54:11,608 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-06-09T12:54:11,609 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:54:16,613 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:54:16,613 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:54:17,854 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:54:17,855 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]8824
2022-06-09T12:54:17,857 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:54:17,857 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:54:17,857 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:54:17,858 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:54:17,858 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:54:17,858 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:54:17,862 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793657862
2022-06-09T12:54:17,862 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:54:17,862 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793657862
2022-06-09T12:54:17,876 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:54:21,078 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:54:21,079 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:54:21,078 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:54:21,079 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:54:21,083 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:54:21,079 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:54:21,081 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:54:21,083 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:54:21,086 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:54:21,084 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:54:21,085 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:54:21,086 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:54:21,088 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:54:21,086 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:54:21,087 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:54:21,088 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:54:21,093 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:54:21,089 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:54:21,092 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:54:21,094 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:54:21,095 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:54:21,093 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:54:21,097 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:54:21,096 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:54:21,097 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:54:21,102 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:54:21,097 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:54:21,103 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:54:21,098 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:54:21,102 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:54:21,103 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-06-09T12:54:21,103 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:54:21,103 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T12:54:21,110 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:54:21,103 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-06-09T12:54:21,110 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:54:29,106 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:54:29,106 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:54:30,445 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:54:30,446 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]21756
2022-06-09T12:54:30,448 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:54:30,448 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:54:30,448 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:54:30,449 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:54:30,448 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:54:30,449 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:54:30,453 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793670453
2022-06-09T12:54:30,453 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:54:30,453 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793670453
2022-06-09T12:54:30,478 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:54:33,532 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:54:33,533 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:54:33,532 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:54:33,533 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:54:33,536 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:54:33,532 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:54:33,535 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:54:33,538 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:54:33,539 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:54:33,536 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:54:33,541 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:54:33,537 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:54:33,540 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:54:33,541 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:54:33,544 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:54:33,542 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:54:33,543 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:54:33,544 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:54:33,546 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:54:33,545 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:54:33,545 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:54:33,546 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:54:33,548 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:54:33,547 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:54:33,547 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T12:54:33,548 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:54:33,555 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:54:33,552 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:54:33,561 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:54:33,554 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service = model_loader.load(
2022-06-09T12:54:33,555 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:54:33,564 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-06-09T12:54:33,561 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:54:33,562 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T12:54:33,566 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:54:33,564 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-06-09T12:54:33,566 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:54:33,750 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 91, in collect_all
    value(num_of_gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 61, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2022-06-09T12:54:33,750 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 91, in collect_all
    value(num_of_gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 61, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2022-06-09T12:54:46,577 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:54:46,577 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:54:47,852 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:54:47,853 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]32388
2022-06-09T12:54:47,854 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:54:47,854 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:54:47,854 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:54:47,855 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:54:47,854 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:54:47,855 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:54:47,859 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793687859
2022-06-09T12:54:47,859 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793687859
2022-06-09T12:54:47,859 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:54:47,871 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:54:51,000 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:54:51,001 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:54:51,000 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:54:51,001 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:54:51,003 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:54:51,000 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:54:51,002 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:54:51,003 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:54:51,006 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:54:51,004 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:54:51,005 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:54:51,006 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:54:51,010 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:54:51,008 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:54:51,009 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:54:51,010 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:54:51,012 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:54:51,010 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:54:51,011 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:54:51,012 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:54:51,014 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:54:51,013 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:54:51,013 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:54:51,016 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:54:51,019 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:54:51,014 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:54:51,026 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:54:51,024 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:54:51,026 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:54:51,027 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-06-09T12:54:51,026 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:54:51,028 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:54:51,027 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T12:54:51,029 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:54:51,027 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-06-09T12:54:51,028 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:54:51,029 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:55:12,034 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:55:12,034 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:55:13,534 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:55:13,536 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]13168
2022-06-09T12:55:13,540 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:55:13,541 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:55:13,541 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:55:13,541 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:55:13,544 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:55:13,544 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:55:13,549 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793713549
2022-06-09T12:55:13,549 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:55:13,549 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793713549
2022-06-09T12:55:13,568 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:55:16,924 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:55:16,924 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:55:16,924 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:55:16,924 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:55:16,927 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:55:16,924 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:55:16,926 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:55:16,927 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:55:16,930 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:55:16,928 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:55:16,929 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:55:16,930 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:55:16,935 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:55:16,931 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:55:16,932 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:55:16,935 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:55:16,937 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:55:16,936 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:55:16,936 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:55:16,937 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:55:16,943 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:55:16,938 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:55:16,942 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:55:16,943 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:55:16,948 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:55:16,947 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:55:16,948 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:55:16,950 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:55:16,948 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:55:16,954 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-06-09T12:55:16,949 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:55:16,957 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:55:16,950 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:55:16,954 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-06-09T12:55:16,957 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:55:33,785 [ERROR] Thread-3 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 91, in collect_all
    value(num_of_gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 61, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2022-06-09T12:55:33,785 [ERROR] Thread-3 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 91, in collect_all
    value(num_of_gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 61, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2022-06-09T12:55:50,964 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:55:50,964 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:55:52,329 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:55:52,330 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]5164
2022-06-09T12:55:52,332 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:55:52,332 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:55:52,332 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:55:52,334 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:55:52,333 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:55:52,334 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:55:52,339 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793752339
2022-06-09T12:55:52,339 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793752339
2022-06-09T12:55:52,339 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:55:52,358 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:55:55,537 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:55:55,538 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:55:55,537 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:55:55,538 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:55:55,543 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:55:55,538 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:55:55,543 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:55:55,544 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:55:55,541 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:55:55,543 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:55:55,544 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:55:55,547 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:55:55,544 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:55:55,546 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:55:55,547 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:55:55,548 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:55:55,548 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:55:55,550 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:55:55,547 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:55:55,548 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:55:55,555 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:55:55,559 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:55:55,550 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:55:55,564 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:55:55,563 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:55:55,564 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:55:55,565 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:55:55,565 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-06-09T12:55:55,563 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:55:55,567 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:55:55,565 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-06-09T12:55:55,565 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:55:55,567 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:56:33,789 [ERROR] Thread-4 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 91, in collect_all
    value(num_of_gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 61, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2022-06-09T12:56:33,789 [ERROR] Thread-4 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 91, in collect_all
    value(num_of_gpu)
  File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\metrics\system_metrics.py", line 61, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2022-06-09T12:56:50,576 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:56:50,576 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\program files\python39\python.exe, C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T12:56:51,846 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T12:56:51,847 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]29300
2022-06-09T12:56:51,847 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:56:51,847 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T12:56:51,847 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T12:56:51,848 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.9.5
2022-06-09T12:56:51,848 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:56:51,848 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T12:56:51,850 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793811850
2022-06-09T12:56:51,850 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654793811850
2022-06-09T12:56:51,851 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T12:56:51,872 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T12:56:54,900 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T12:56:54,900 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:56:54,900 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T12:56:54,900 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T12:56:54,904 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:56:54,900 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:56:54,904 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T12:56:54,904 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T12:56:54,906 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:56:54,905 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:56:54,906 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T12:56:54,906 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T12:56:54,911 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:56:54,907 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T12:56:54,908 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T12:56:54,911 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:56:54,911 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T12:56:54,914 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:56:54,912 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T12:56:54,913 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:56:54,914 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T12:56:54,916 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:56:54,915 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T12:56:54,915 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:56:54,916 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T12:56:54,921 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:56:54,921 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T12:56:54,923 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-06-09T12:56:54,919 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Roaming\Python\Python39\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T12:56:54,925 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:56:54,921 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T12:56:54,929 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T12:56:54,923 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-06-09T12:56:54,925 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T12:56:54,929 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:07:30,526 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-06-09T13:07:30,526 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-06-09T13:07:30,842 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-06-09T13:07:30,842 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-06-09T13:07:32,138 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.6.0
TS Home: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages
Current directory: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment
Temp directory: C:\Users\steph\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 8180 M
Python executable: c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe
Config file: logs\config\20220609125331387-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Initial Models: license_plate=license_plate.mar
Log dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Metrics dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Model config: N/A
2022-06-09T13:07:32,138 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.6.0
TS Home: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages
Current directory: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment
Temp directory: C:\Users\steph\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 8180 M
Python executable: c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe
Config file: logs\config\20220609125331387-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Initial Models: license_plate=license_plate.mar
Log dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Metrics dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Model config: N/A
2022-06-09T13:07:32,161 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220609125331387-startup.cfg",
  "modelCount": 1,
  "created": 1654793611388,
  "models": {
    "license_plate": {
      "1.0": {
        "defaultVersion": true,
        "marName": "license_plate.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-06-09T13:07:32,161 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220609125331387-startup.cfg",
  "modelCount": 1,
  "created": 1654793611388,
  "models": {
    "license_plate": {
      "1.0": {
        "defaultVersion": true,
        "marName": "license_plate.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-06-09T13:07:32,180 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220609125331387-startup.cfg
2022-06-09T13:07:32,180 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220609125331387-startup.cfg
2022-06-09T13:07:32,182 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220609125331387-startup.cfg validated successfully
2022-06-09T13:07:32,182 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220609125331387-startup.cfg validated successfully
2022-06-09T13:07:32,998 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model license_plate
2022-06-09T13:07:32,998 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model license_plate
2022-06-09T13:07:32,999 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:07:32,999 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:07:33,001 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:07:33,001 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:07:33,002 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model license_plate loaded.
2022-06-09T13:07:33,002 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model license_plate loaded.
2022-06-09T13:07:33,004 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: license_plate, count: 1
2022-06-09T13:07:33,004 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: license_plate, count: 1
2022-06-09T13:07:33,028 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:07:33,029 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-06-09T13:07:33,028 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:07:33,029 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-06-09T13:07:34,465 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T13:07:34,467 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]33312
2022-06-09T13:07:34,468 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T13:07:34,469 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change null -> WORKER_STARTED
2022-06-09T13:07:34,469 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.8.0
2022-06-09T13:07:34,469 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change null -> WORKER_STARTED
2022-06-09T13:07:34,479 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:07:34,479 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:07:35,113 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-06-09T13:07:35,113 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-06-09T13:07:35,113 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-06-09T13:07:35,113 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-06-09T13:07:35,118 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-06-09T13:07:35,118 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T13:07:35,118 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-06-09T13:07:35,120 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-06-09T13:07:35,120 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-06-09T13:07:35,123 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-06-09T13:07:35,123 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-06-09T13:07:35,125 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794455125
2022-06-09T13:07:35,125 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794455125
2022-06-09T13:07:35,178 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T13:07:38,722 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:18.8|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794458
2022-06-09T13:07:38,736 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:56.788089752197266|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794458
2022-06-09T13:07:38,740 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:408.3720359802246|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794458
2022-06-09T13:07:38,741 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:87.8|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794458
2022-06-09T13:07:38,742 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:24.462890625|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654794458
2022-06-09T13:07:38,743 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2004|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654794458
2022-06-09T13:07:38,743 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:5|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654794458
2022-06-09T13:07:38,744 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:8872.59375|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794458
2022-06-09T13:07:38,745 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:23846.1953125|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794458
2022-06-09T13:07:38,746 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:72.9|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794458
2022-06-09T13:07:38,747 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T13:07:38,747 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T13:07:38,748 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:07:38,751 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:07:38,751 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:07:38,750 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:07:38,753 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T13:07:38,754 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:07:38,755 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:07:38,749 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:07:38,755 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:07:38,755 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:07:38,756 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:07:38,756 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:07:38,757 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:07:38,763 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:07:38,764 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service = model_loader.load(
2022-06-09T13:07:38,765 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T13:07:38,766 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-06-09T13:07:38,767 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 180, in <lambda>
2022-06-09T13:07:38,767 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-06-09T13:07:38,768 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - TypeError: handle() takes 1 positional argument but 2 were given
2022-06-09T13:07:38,762 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T13:07:38,772 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:07:38,779 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:07:38,782 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:07:38,757 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:07:38,757 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:07:38,785 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:07:38,786 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:07:38,786 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:07:38,787 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:07:38,786 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:07:38,787 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:07:38,790 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:07:38,789 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service = model_loader.load(
2022-06-09T13:07:38,790 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:07:38,794 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:07:38,793 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T13:07:38,795 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:07:38,794 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:07:38,795 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:07:38,798 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T13:07:38,798 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T13:07:38,816 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:07:38,816 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:07:39,814 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:07:39,814 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:07:41,010 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T13:07:41,011 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]9924
2022-06-09T13:07:41,015 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:07:41,015 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T13:07:41,015 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:07:41,016 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:07:41,016 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.8.0
2022-06-09T13:07:41,016 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:07:41,022 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794461021
2022-06-09T13:07:41,022 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794461021
2022-06-09T13:07:41,022 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T13:07:41,035 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T13:07:44,105 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:07:44,104 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T13:07:44,105 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:07:44,113 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:07:44,104 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T13:07:44,105 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:07:44,113 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:07:44,113 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:07:44,116 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:07:44,114 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:07:44,115 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:07:44,117 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T13:07:44,116 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:07:44,119 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:07:44,117 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T13:07:44,118 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:07:44,119 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:07:44,121 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:07:44,120 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:07:44,120 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:07:44,121 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:07:44,124 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:07:44,122 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:07:44,123 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:07:44,125 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:07:44,124 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:07:44,127 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:07:44,127 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:07:44,136 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:07:44,126 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:07:44,136 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:07:44,137 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service = model_loader.load(
2022-06-09T13:07:44,138 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T13:07:44,139 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-06-09T13:07:44,139 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 180, in <lambda>
2022-06-09T13:07:44,140 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-06-09T13:07:44,136 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:07:44,141 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - TypeError: handle() takes 1 positional argument but 2 were given
2022-06-09T13:07:44,127 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:07:44,145 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T13:07:44,145 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T13:07:44,155 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:07:44,155 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:07:45,159 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:07:45,159 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:07:46,264 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T13:07:46,265 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]21256
2022-06-09T13:07:46,267 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:07:46,267 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T13:07:46,267 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:07:46,268 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:07:46,268 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.8.0
2022-06-09T13:07:46,268 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:07:46,273 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794466273
2022-06-09T13:07:46,273 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T13:07:46,273 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794466273
2022-06-09T13:07:46,286 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T13:07:49,387 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T13:07:49,387 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T13:07:49,387 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:07:49,388 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:07:49,388 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:07:49,388 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:07:49,387 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:07:49,389 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:07:49,388 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:07:49,388 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T13:07:49,389 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:07:49,390 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:07:49,389 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:07:49,389 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T13:07:49,391 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:07:49,394 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:07:49,391 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:07:49,395 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:07:49,390 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:07:49,397 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:07:49,396 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:07:49,397 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:07:49,399 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:07:49,397 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:07:49,398 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:07:49,399 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:07:49,400 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:07:49,399 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:07:49,403 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:07:49,401 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service = model_loader.load(
2022-06-09T13:07:49,403 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:07:49,410 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:07:49,402 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service = model_loader.load(
2022-06-09T13:07:49,410 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T13:07:49,412 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:07:49,410 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:07:49,412 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-06-09T13:07:49,411 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T13:07:49,413 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:07:49,412 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:07:49,412 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-06-09T13:07:49,413 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:07:51,414 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:07:51,414 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:07:52,649 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T13:07:52,650 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]16176
2022-06-09T13:07:52,650 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:07:52,650 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T13:07:52,650 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:07:52,650 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.8.0
2022-06-09T13:07:52,650 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:07:52,650 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:07:52,653 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794472653
2022-06-09T13:07:52,653 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794472653
2022-06-09T13:07:52,653 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T13:07:52,671 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T13:07:55,844 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T13:07:55,844 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:07:55,844 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T13:07:55,844 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:07:55,844 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:07:55,845 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:07:55,845 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:07:55,845 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:07:55,845 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:07:55,845 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:07:55,846 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T13:07:55,846 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T13:07:55,846 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:07:55,846 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:07:55,846 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:07:55,846 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:07:55,847 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:07:55,847 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:07:55,849 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:07:55,849 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:07:55,849 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:07:55,849 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:07:55,849 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:07:55,849 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:07:55,850 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:07:55,850 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:07:55,850 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:07:55,850 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:07:55,850 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:07:55,850 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:07:55,851 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:07:55,850 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service = model_loader.load(
2022-06-09T13:07:55,851 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service = model_loader.load(
2022-06-09T13:07:55,851 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:07:55,851 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:07:55,851 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:07:55,852 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-06-09T13:07:55,851 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T13:07:55,852 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-06-09T13:07:55,852 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:07:55,852 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:07:58,866 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:07:58,866 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:09:40,274 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-06-09T13:09:40,274 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-06-09T13:09:40,424 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-06-09T13:09:40,424 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-06-09T13:09:41,532 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.6.0
TS Home: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages
Current directory: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment
Temp directory: C:\Users\steph\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 8180 M
Python executable: c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe
Config file: logs\config\20220609130735124-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Initial Models: license_plate=license_plate.mar
Log dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Metrics dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Model config: N/A
2022-06-09T13:09:41,532 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.6.0
TS Home: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages
Current directory: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment
Temp directory: C:\Users\steph\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 8180 M
Python executable: c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe
Config file: logs\config\20220609130735124-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Initial Models: license_plate=license_plate.mar
Log dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Metrics dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Model config: N/A
2022-06-09T13:09:41,545 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220609130735124-startup.cfg",
  "modelCount": 1,
  "created": 1654794455125,
  "models": {
    "license_plate": {
      "1.0": {
        "defaultVersion": true,
        "marName": "license_plate.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-06-09T13:09:41,545 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220609130735124-startup.cfg",
  "modelCount": 1,
  "created": 1654794455125,
  "models": {
    "license_plate": {
      "1.0": {
        "defaultVersion": true,
        "marName": "license_plate.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-06-09T13:09:41,557 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220609130735124-startup.cfg
2022-06-09T13:09:41,557 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220609130735124-startup.cfg
2022-06-09T13:09:41,559 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220609130735124-startup.cfg validated successfully
2022-06-09T13:09:41,559 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220609130735124-startup.cfg validated successfully
2022-06-09T13:09:42,337 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model license_plate
2022-06-09T13:09:42,337 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model license_plate
2022-06-09T13:09:42,338 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:09:42,338 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:09:42,339 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:09:42,339 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:09:42,340 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model license_plate loaded.
2022-06-09T13:09:42,340 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model license_plate loaded.
2022-06-09T13:09:42,341 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: license_plate, count: 1
2022-06-09T13:09:42,341 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: license_plate, count: 1
2022-06-09T13:09:42,364 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-06-09T13:09:42,364 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-06-09T13:09:42,364 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:09:42,364 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:09:43,723 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T13:09:43,724 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]34100
2022-06-09T13:09:43,726 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T13:09:43,727 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change null -> WORKER_STARTED
2022-06-09T13:09:43,727 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.8.0
2022-06-09T13:09:43,727 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change null -> WORKER_STARTED
2022-06-09T13:09:43,736 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:09:43,736 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:09:44,305 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-06-09T13:09:44,305 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-06-09T13:09:44,306 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-06-09T13:09:44,306 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-06-09T13:09:44,310 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-06-09T13:09:44,310 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-06-09T13:09:44,311 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-06-09T13:09:44,311 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-06-09T13:09:44,312 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T13:09:44,313 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-06-09T13:09:44,313 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-06-09T13:09:44,318 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794584318
2022-06-09T13:09:44,318 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794584318
2022-06-09T13:09:44,363 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T13:09:47,754 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794587
2022-06-09T13:09:47,757 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:56.77547073364258|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794587
2022-06-09T13:09:47,760 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:408.3846549987793|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794587
2022-06-09T13:09:47,762 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:87.8|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794587
2022-06-09T13:09:47,762 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:24.40185546875|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654794587
2022-06-09T13:09:47,763 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1999|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654794587
2022-06-09T13:09:47,765 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:5|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654794587
2022-06-09T13:09:47,766 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:8874.9609375|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794587
2022-06-09T13:09:47,768 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:23843.828125|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794587
2022-06-09T13:09:47,768 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:72.9|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654794587
2022-06-09T13:09:48,416 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - This is context <ts.context.Context object at 0x00000149FBA33DC0>
2022-06-09T13:09:48,416 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T13:09:48,419 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:09:48,417 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - This is context sys properties {'model_dir': 'C:\\Users\\steph\\AppData\\Local\\Temp\\models\\98f951519b6644da98eff0266f513ca8', 'gpu_id': 0, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.6.0', 'limit_max_image_pixels': True}
2022-06-09T13:09:48,419 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:09:48,419 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T13:09:48,419 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:09:48,422 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:09:48,420 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:09:48,421 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:09:48,422 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:09:48,423 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:09:48,423 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T13:09:48,424 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T13:09:48,425 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:09:48,427 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:09:48,426 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:09:48,429 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:09:48,429 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:09:48,430 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:09:48,431 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:09:48,431 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:09:48,432 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service = model_loader.load(
2022-06-09T13:09:48,433 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:09:48,434 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T13:09:48,439 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:09:48,441 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     initialize_fn(service.context)
2022-06-09T13:09:48,423 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:09:48,441 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service = model_loader.load(
2022-06-09T13:09:48,443 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 180, in <lambda>
2022-06-09T13:09:48,444 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 151, in load
2022-06-09T13:09:48,423 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:09:48,445 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-06-09T13:09:48,447 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:09:48,445 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-06-09T13:09:48,447 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\AppData\Local\Temp\models\98f951519b6644da98eff0266f513ca8\my_handler.py", line 109, in handle
2022-06-09T13:09:48,447 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:09:48,449 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:09:48,448 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\model_loader.py", line 180, in <lambda>
2022-06-09T13:09:48,448 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     _service.initialize(context)
2022-06-09T13:09:48,449 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:09:48,455 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:09:48,450 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-06-09T13:09:48,454 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\lib\site-packages\ts\torch_handler\base_handler.py", line 91, in initialize
2022-06-09T13:09:48,455 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:09:48,461 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:09:48,456 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\AppData\Local\Temp\models\98f951519b6644da98eff0266f513ca8\my_handler.py", line 109, in handle
2022-06-09T13:09:48,458 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.model = self._load_torchscript_model(model_pt_path)
2022-06-09T13:09:48,463 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:09:48,461 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:09:48,464 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T13:09:48,462 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-06-09T13:09:48,464 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:09:48,463 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:09:48,464 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:09:48,464 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T13:09:49,480 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:09:49,480 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:09:50,662 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T13:09:50,663 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]11824
2022-06-09T13:09:50,665 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:09:50,665 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T13:09:50,665 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:09:50,667 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:09:50,666 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.8.0
2022-06-09T13:09:50,667 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:09:50,671 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794590671
2022-06-09T13:09:50,671 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794590671
2022-06-09T13:09:50,672 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T13:09:50,684 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T13:09:54,502 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - This is context <ts.context.Context object at 0x0000013095DB3D00>
2022-06-09T13:09:54,503 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:09:54,502 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - This is context sys properties {'model_dir': 'C:\\Users\\steph\\AppData\\Local\\Temp\\models\\98f951519b6644da98eff0266f513ca8', 'gpu_id': 0, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.6.0', 'limit_max_image_pixels': True}
2022-06-09T13:09:54,503 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:09:54,505 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:09:54,502 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T13:09:54,505 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T13:09:54,505 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:09:54,508 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:09:54,507 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:09:54,507 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:09:54,508 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:09:54,511 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:09:54,509 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:09:54,510 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:09:54,511 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:09:54,513 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:09:54,512 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T13:09:54,513 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T13:09:54,513 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:09:54,515 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:09:54,514 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:09:54,515 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:09:54,515 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:09:54,522 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:09:54,516 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:09:54,523 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:09:54,517 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:09:54,522 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:09:54,524 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T13:09:54,523 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:09:54,523 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:09:54,526 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:09:54,524 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-06-09T13:09:54,526 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:09:55,538 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:09:55,538 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:09:56,735 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T13:09:56,736 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]31948
2022-06-09T13:09:56,738 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:09:56,738 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T13:09:56,738 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:09:56,740 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:09:56,739 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.8.0
2022-06-09T13:09:56,740 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:09:56,744 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794596744
2022-06-09T13:09:56,744 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794596744
2022-06-09T13:09:56,744 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T13:09:56,757 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T13:10:00,666 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - This is context <ts.context.Context object at 0x0000026AE7854D00>
2022-06-09T13:10:00,666 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:10:00,666 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T13:10:00,666 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:10:00,670 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:10:00,666 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - This is context sys properties {'model_dir': 'C:\\Users\\steph\\AppData\\Local\\Temp\\models\\98f951519b6644da98eff0266f513ca8', 'gpu_id': 0, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.6.0', 'limit_max_image_pixels': True}
2022-06-09T13:10:00,669 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:10:00,670 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:10:00,672 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:10:00,671 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T13:10:00,672 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:10:00,672 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:10:00,675 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:10:00,673 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:10:00,674 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T13:10:00,675 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:10:00,677 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:10:00,677 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:10:00,677 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:10:00,677 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:10:00,679 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:10:00,678 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:10:00,678 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T13:10:00,679 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:10:00,686 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:10:00,680 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:10:00,682 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:10:00,690 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:10:00,686 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:10:00,691 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-06-09T13:10:00,690 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:10:00,691 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:10:00,690 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:10:00,691 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-06-09T13:10:00,691 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:10:02,698 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:10:02,698 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:10:03,867 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T13:10:03,868 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]27100
2022-06-09T13:10:03,869 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:10:03,869 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T13:10:03,869 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-06-09T13:10:03,870 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:10:03,870 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.8.0
2022-06-09T13:10:03,870 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:10:03,874 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794603874
2022-06-09T13:10:03,874 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654794603874
2022-06-09T13:10:03,875 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T13:10:03,888 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T13:10:07,864 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - This is context <ts.context.Context object at 0x000001F3C62E4D00>
2022-06-09T13:10:07,864 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:10:07,864 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - This is context sys properties {'model_dir': 'C:\\Users\\steph\\AppData\\Local\\Temp\\models\\98f951519b6644da98eff0266f513ca8', 'gpu_id': 0, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.6.0', 'limit_max_image_pixels': True}
2022-06-09T13:10:07,864 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Backend worker process died.
2022-06-09T13:10:07,864 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-06-09T13:10:07,865 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Backend worker process died.
2022-06-09T13:10:07,865 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:10:07,865 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:10:07,865 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-06-09T13:10:07,865 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-06-09T13:10:07,865 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:10:07,865 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:10:07,866 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 210, in <module>
2022-06-09T13:10:07,866 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     worker.run_server()
2022-06-09T13:10:07,865 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2022-06-09T13:10:07,866 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:10:07,866 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     worker.run_server()
2022-06-09T13:10:07,867 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:10:07,867 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:10:07,867 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: license_plate, error: Worker died.
2022-06-09T13:10:07,867 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:10:07,867 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 181, in run_server
2022-06-09T13:10:07,867 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:10:07,867 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-06-09T13:10:07,867 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-06-09T13:10:07,867 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:10:07,868 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:10:07,868 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 139, in handle_connection
2022-06-09T13:10:07,868 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:10:07,868 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stderr
2022-06-09T13:10:07,875 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:10:07,870 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-06-09T13:10:07,874 [WARN ] W-9000-license_plate_1.0-stderr MODEL_LOG -     service = model_loader.load(
2022-06-09T13:10:07,876 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:10:07,875 [WARN ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-license_plate_1.0-stdout
2022-06-09T13:10:07,877 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-06-09T13:10:07,875 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG -   File "C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py", line 104, in load_model
2022-06-09T13:10:07,878 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:10:07,876 [INFO ] W-9000-license_plate_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stderr
2022-06-09T13:10:07,877 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-06-09T13:10:07,878 [INFO ] W-9000-license_plate_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-license_plate_1.0-stdout
2022-06-09T13:19:29,375 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-06-09T13:19:29,375 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-06-09T13:19:29,527 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-06-09T13:19:29,527 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-06-09T13:19:30,677 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.6.0
TS Home: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages
Current directory: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment
Temp directory: C:\Users\steph\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 8180 M
Python executable: c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe
Config file: logs\config\20220609130944314-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Initial Models: license_plate=license_plate.mar
Log dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Metrics dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Model config: N/A
2022-06-09T13:19:30,677 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.6.0
TS Home: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages
Current directory: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment
Temp directory: C:\Users\steph\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 8180 M
Python executable: c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe
Config file: logs\config\20220609130944314-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Initial Models: license_plate=license_plate.mar
Log dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Metrics dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Model config: N/A
2022-06-09T13:19:30,694 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220609130944314-startup.cfg",
  "modelCount": 1,
  "created": 1654794584315,
  "models": {
    "license_plate": {
      "1.0": {
        "defaultVersion": true,
        "marName": "license_plate.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-06-09T13:19:30,694 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220609130944314-startup.cfg",
  "modelCount": 1,
  "created": 1654794584315,
  "models": {
    "license_plate": {
      "1.0": {
        "defaultVersion": true,
        "marName": "license_plate.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-06-09T13:19:30,709 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220609130944314-startup.cfg
2022-06-09T13:19:30,709 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220609130944314-startup.cfg
2022-06-09T13:19:30,712 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220609130944314-startup.cfg validated successfully
2022-06-09T13:19:30,712 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220609130944314-startup.cfg validated successfully
2022-06-09T13:19:31,529 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model license_plate
2022-06-09T13:19:31,529 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model license_plate
2022-06-09T13:19:31,530 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:19:31,530 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:19:31,530 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:19:31,530 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:19:31,531 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model license_plate loaded.
2022-06-09T13:19:31,531 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model license_plate loaded.
2022-06-09T13:19:31,531 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: license_plate, count: 1
2022-06-09T13:19:31,531 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: license_plate, count: 1
2022-06-09T13:19:31,547 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-06-09T13:19:31,547 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-06-09T13:19:31,549 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:19:31,549 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:19:32,885 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T13:19:32,887 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]16736
2022-06-09T13:19:32,887 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T13:19:32,888 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.8.0
2022-06-09T13:19:32,888 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change null -> WORKER_STARTED
2022-06-09T13:19:32,888 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change null -> WORKER_STARTED
2022-06-09T13:19:32,896 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:19:32,896 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:19:33,536 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-06-09T13:19:33,536 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-06-09T13:19:33,537 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-06-09T13:19:33,537 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-06-09T13:19:33,540 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T13:19:33,546 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-06-09T13:19:33,546 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-06-09T13:19:33,547 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-06-09T13:19:33,547 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-06-09T13:19:33,550 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654795173550
2022-06-09T13:19:33,550 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-06-09T13:19:33,550 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654795173550
2022-06-09T13:19:33,550 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-06-09T13:19:33,594 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T13:19:36,990 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795176
2022-06-09T13:19:36,992 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:56.76459884643555|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795176
2022-06-09T13:19:36,996 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:408.3955268859863|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795176
2022-06-09T13:19:36,997 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:87.8|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795176
2022-06-09T13:19:36,999 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:24.8046875|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795176
2022-06-09T13:19:37,000 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2032|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795176
2022-06-09T13:19:37,001 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:6|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795176
2022-06-09T13:19:37,002 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:9178.27734375|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795176
2022-06-09T13:19:37,004 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:23540.51171875|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795176
2022-06-09T13:19:37,010 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:71.9|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795176
2022-06-09T13:19:37,529 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3935
2022-06-09T13:19:37,529 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3935
2022-06-09T13:19:37,530 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-06-09T13:19:37,530 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-06-09T13:19:37,532 [INFO ] W-9000-license_plate_1.0 TS_METRICS - W-9000-license_plate_1.0.ms:5991|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795177
2022-06-09T13:19:37,534 [INFO ] W-9000-license_plate_1.0 TS_METRICS - WorkerThreadTime.ms:49|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795177
2022-06-09T13:20:36,996 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795236
2022-06-09T13:20:36,997 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:56.76445770263672|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795236
2022-06-09T13:20:37,001 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:408.39566802978516|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795236
2022-06-09T13:20:37,004 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:87.8|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795236
2022-06-09T13:20:37,006 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:25.20751953125|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795236
2022-06-09T13:20:37,007 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2065|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795236
2022-06-09T13:20:37,009 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:8|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795236
2022-06-09T13:20:37,010 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:9199.02734375|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795236
2022-06-09T13:20:37,011 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:23519.76171875|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795236
2022-06-09T13:20:37,012 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:71.9|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795236
2022-06-09T13:21:36,943 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795296
2022-06-09T13:21:36,944 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:56.76271057128906|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795296
2022-06-09T13:21:36,950 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:408.3974151611328|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795296
2022-06-09T13:21:36,951 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:87.8|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795296
2022-06-09T13:21:36,951 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:24.91455078125|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795296
2022-06-09T13:21:36,953 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2041|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795296
2022-06-09T13:21:36,953 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:17|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795296
2022-06-09T13:21:36,954 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:9027.91015625|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795296
2022-06-09T13:21:36,955 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:23690.87890625|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795296
2022-06-09T13:21:36,956 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:72.4|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795296
2022-06-09T13:22:36,950 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795356
2022-06-09T13:22:36,951 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:56.763248443603516|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795356
2022-06-09T13:22:36,952 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:408.39687728881836|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795356
2022-06-09T13:22:36,952 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:87.8|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795356
2022-06-09T13:22:36,953 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:25.146484375|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795356
2022-06-09T13:22:36,953 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:2060|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795356
2022-06-09T13:22:36,953 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:5|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795356
2022-06-09T13:22:36,954 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:8842.234375|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795356
2022-06-09T13:22:36,954 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:23876.5546875|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795356
2022-06-09T13:22:36,954 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:73.0|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795356
2022-06-09T13:22:58,429 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-06-09T13:22:58,429 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-06-09T13:22:58,582 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-06-09T13:22:58,582 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-06-09T13:22:59,743 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.6.0
TS Home: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages
Current directory: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment
Temp directory: C:\Users\steph\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 8180 M
Python executable: c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe
Config file: logs\config\20220609131933553-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Initial Models: license_plate=license_plate.mar
Log dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Metrics dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Model config: N/A
2022-06-09T13:22:59,743 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.6.0
TS Home: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages
Current directory: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment
Temp directory: C:\Users\steph\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 8180 M
Python executable: c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe
Config file: logs\config\20220609131933553-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Initial Models: license_plate=license_plate.mar
Log dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Metrics dir: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\model-store
Model config: N/A
2022-06-09T13:22:59,759 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220609131933553-startup.cfg",
  "modelCount": 1,
  "created": 1654795173554,
  "models": {
    "license_plate": {
      "1.0": {
        "defaultVersion": true,
        "marName": "license_plate.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-06-09T13:22:59,759 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220609131933553-startup.cfg",
  "modelCount": 1,
  "created": 1654795173554,
  "models": {
    "license_plate": {
      "1.0": {
        "defaultVersion": true,
        "marName": "license_plate.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-06-09T13:22:59,775 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220609131933553-startup.cfg
2022-06-09T13:22:59,775 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220609131933553-startup.cfg
2022-06-09T13:22:59,778 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220609131933553-startup.cfg validated successfully
2022-06-09T13:22:59,778 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220609131933553-startup.cfg validated successfully
2022-06-09T13:23:00,672 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model license_plate
2022-06-09T13:23:00,672 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model license_plate
2022-06-09T13:23:00,673 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:23:00,673 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:23:00,673 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:23:00,673 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model license_plate
2022-06-09T13:23:00,674 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model license_plate loaded.
2022-06-09T13:23:00,674 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model license_plate loaded.
2022-06-09T13:23:00,674 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: license_plate, count: 1
2022-06-09T13:23:00,674 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: license_plate, count: 1
2022-06-09T13:23:00,699 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-06-09T13:23:00,699 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-06-09T13:23:00,700 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:23:00,700 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\steph\onedrive - the university of the west indies, st. augustine\ttlabs\license plate recognition\deployment\venv3.8\scripts\python.exe, C:\Users\steph\OneDrive - The University of the West Indies, St. Augustine\TTLABS\License Plate Recognition\Deployment\venv3.8\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-06-09T13:23:02,233 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Listening on port: None
2022-06-09T13:23:02,234 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - [PID]24520
2022-06-09T13:23:02,235 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Torch worker started.
2022-06-09T13:23:02,235 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change null -> WORKER_STARTED
2022-06-09T13:23:02,235 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Python runtime: 3.8.0
2022-06-09T13:23:02,235 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change null -> WORKER_STARTED
2022-06-09T13:23:02,243 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:23:02,243 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-06-09T13:23:02,996 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-06-09T13:23:02,996 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-06-09T13:23:02,997 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-06-09T13:23:02,997 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-06-09T13:23:03,001 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-06-09T13:23:03,002 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-06-09T13:23:03,002 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-06-09T13:23:03,003 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-06-09T13:23:03,003 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-06-09T13:23:03,005 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-06-09T13:23:03,005 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-06-09T13:23:03,006 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654795383006
2022-06-09T13:23:03,006 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1654795383006
2022-06-09T13:23:03,039 [INFO ] W-9000-license_plate_1.0-stdout MODEL_LOG - model_name: license_plate, batchSize: 1
2022-06-09T13:23:05,817 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795385
2022-06-09T13:23:05,818 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:56.73401641845703|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795385
2022-06-09T13:23:05,821 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:408.42610931396484|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795385
2022-06-09T13:23:05,822 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:87.8|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795385
2022-06-09T13:23:05,824 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:24.8291015625|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795385
2022-06-09T13:23:05,824 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2034|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795385
2022-06-09T13:23:05,825 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:4|#Level:Host,device_id:0|#hostname:DESKTOP-7GSK822,timestamp:1654795385
2022-06-09T13:23:05,826 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:10219.1796875|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795385
2022-06-09T13:23:05,828 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:22499.609375|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795385
2022-06-09T13:23:05,829 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:68.8|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795385
2022-06-09T13:23:06,244 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3202
2022-06-09T13:23:06,244 [INFO ] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3202
2022-06-09T13:23:06,244 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-06-09T13:23:06,244 [DEBUG] W-9000-license_plate_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-license_plate_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-06-09T13:23:06,246 [INFO ] W-9000-license_plate_1.0 TS_METRICS - W-9000-license_plate_1.0.ms:5557|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795386
2022-06-09T13:23:06,248 [INFO ] W-9000-license_plate_1.0 TS_METRICS - WorkerThreadTime.ms:39|#Level:Host|#hostname:DESKTOP-7GSK822,timestamp:1654795386
